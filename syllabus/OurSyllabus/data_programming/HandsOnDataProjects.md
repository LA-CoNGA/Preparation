# Hands on Data Projects (HEP specialisation only )

Instructor(s): To be defined

Number of ECTS: 3

Number of hours: 75h of hands on practical work over 6 weeks.

## Course description

Two hands on exercises:

* One exercise will be based in HEP open data (3 weeks)
* Another exercise in a dataset coming from industry/non-academic environments (3 weeks)

All students will do both exercises. There can be cases of one larger project taking all the 6 weeks. 

### Topic overview

A pool of projects will be made available to the students using datasets from different fiels: experimental particle physics (LHC experiments, LAGO), Kaggle challenges or datasetse from our industry partners. There will be a mentor assigned to each projects.

## Pre-requisites/Co-requisites

Students should have followed the Statistics and Research Software Engineering courses.

## Schedule

### Class Structure
* Academic projects will be developed during weeks 1-3 while non academic projects will be developed between weeks 4-6
* The frequency of meetings/discussion sessions will be decided between the students and the mentors of the corresponding project

### Assessments
The assessment of this module is based on a presentation and a report of the project's results.  
Students are expected to submit a short report and their code. The purpose of the report is to answer the non-coding questions, to present results and provide a brief description of design choices and implementation. 
This correspond to 30% of the total grade for the data science module.

## Pool of projects (this list is still growing)

### Project title: ‘AI Commons’: A framework for collaboration to achieve global impact

Responsable: 

Duration: 3 weeks

Dataset: Need to contact the community to get the datasets. These are datasets released in collaboration with the UN.

Objectives: A common knowledge hub to accelerate the world’s challenges with Artificial Intelligence

Comments: it might be better to use these datasets for the AI course in the second semester. Here is the link: https://ai-commons.org


### Project title: New York City Airbnb Open Data

Responsable: 

Duration: 3 weeks

Dataset: kaggle challenge (https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)

Objectives: This data file includes all needed information to find out more about hosts, geographical availability, necessary metrics to make predictions and draw conclusions. 

Comments: There is also the possiblity of having some data criminality statistics for the city of London. 


### Project title: Scientific computing: design and deploy of physics data analysis pipelines with in-house and cloud computing.

Responsable: 

Duration: 3 weeks or 6 weeks (the complexity can be calibrated)

Dataset: LHC experiments Open Data at 8 and 13 TeV 

Objectives: 
* With the development of a physics analysis (HEP for example)
    * Train the student to design data analysis in terms of the resources, the procedures, versioning and maintainability.
    * Develop a culture of reproducibility and proper analysis development protocols.
    * Get into the so-called "Big Data" by prototyping analysis using Open Data.
    * Present the final products in a modern way, under the proper licensing and DOI identification.

### Project title: Analysis of Higgs boson decays to two tau leptons using data and simulation of events at the CMS detector from 2012

Responsable: 

Duration: 3 weeks 

Dataset: CMS open data

Objectives: This analysis uses data and simulation of events at the CMS experiment from 2012 with the goal to study decays of a Higgs boson into two tau leptons in the final state of a muon lepton and a hadronically decayed tau lepton. The analysis follows loosely the setup of the official CMS analysis published in 2014.

### Project title: Sample with tracker hit information for tracking algorithm ML studies TTbar_13TeV_PU50_PixelSeeds

Responsable: 

Duration: 3 weeks

Dataset: CMS open data

Objectives: This dataset consists of a collection of pixel doublet seeds, i.e. the hit pairs that could belong to the same particle flying through the CMS Silicon Pixel Detector. These can be used in ML studies of particle tracking algorithms. Particle tracking is the process of clustering the recorded hits into groups of points arranged along an helix.


### Project title: Study of boosted Z→ee using fat electrons

Responsable: 

Duration: 6 weeks

Dataset: ATLAS data

Objectives: For the search of a heavy resonance that decays X → WZ → lvll, the acceptance×efficiency of the analysis decreases for electrons above signal mass ∼ 2 TeV. The loss occurs as electrons are boosted and get closer together and are removed by the usual electron isolation requirements. Different approaches to recover those events are currently under study. During this bachelor thesis we will study the different approaches and investigate the potential gain of including boosted Z→ee events in our search.


### Project title: Data driven backgrounds for same charge WW analysis

Responsable: 

Duration: 6 weeks

Dataset: ATLAS data

Objectives: In the scattering of two W bosons of same charge an important background comes from other processes like ttbar or W+jets, when one of the jets is mis-identified as a lepton. The modelling in usual simulations is not accurate enough motivating more complex approaches to estimate this background from measured data. During this bachelor thesis we will study some aspects of this approach in detail to improve the overall modelling.


### Project title: Validation of Simulations in the scattering of two same charge W bosons

Responsable: 

Duration: 6 weeks

Dataset: ATLAS data

Objectives: In the last year, new simulations became available which increase the theoretical accuracy for simulations of the scattering of two W bosons with the same charge. These new simulations can only be used, once properly validated. During this bachelor thesis, we will for the first time validate these new simulations and compare them to earlier simulations.


## Course material

Will be provided by each mentor
